import tensorflow as tf
from tensorflow.keras.optimizers.legacy import Adam
import os

from utils.models_generator_critic import build_generator, build_critic
from utils.wgan_gp_model import WGANGPModel
from utils.data_loader import DataLoader

if __name__ == '__main__':

    # Instantiate models
    generator = build_generator()
    critic = build_critic()

    # Define optimizers
    generator_optimizer = Adam(0.0001, beta_1=0.5, beta_2=0.9)
    critic_optimizer = Adam(0.0001, beta_1=0.5, beta_2=0.9)

    # Define hyperparameters
    batch_size = 32
    embedding_size = 768
    n_critic = 5  # Training the critic more often than the generator # TODO: 100 according to paper
    lambda_gp = 10

    # Define directories
    checkpoint_dir = os.path.join(os.getcwd(), 'checkpoints_zeroaccess')
    os.makedirs(checkpoint_dir, exist_ok=True)
    logs_dir = os.path.join(os.getcwd(), 'logs_zeroaccess')
    os.makedirs(logs_dir, exist_ok=True)
    intermediary_malware_dir = os.path.join(os.getcwd(), 'intermediary_malware_zeroaccess')
    os.makedirs(intermediary_malware_dir, exist_ok=True)

    # Create WGAN-GP model instance
    wgan_gp = WGANGPModel(
        generator, 
        critic, 
        generator_optimizer, 
        critic_optimizer, 
        checkpoint_dir, 
        logs_dir, 
        intermediary_malware_dir,
        batch_size,
        embedding_size,
        n_critic,
        lambda_gp
    )

    # Example dataset (replace with your actual dataset)
    malware_embeddings_path = os.path.join(os.getcwd(), "distelBERT_embeddings/Malicia (Big 3 - Opcodes)/zeroaccess/tensor_embedding.npy")
    data_loader = DataLoader(malware_embeddings_path, batch_size)
    dataset = data_loader.load_data()

    # Train the model
    wgan_gp.train(dataset, epochs=500)

    # Generate fake data
    fake_data = wgan_gp.generate_fake_data(num_samples=10)
    print(fake_data)
